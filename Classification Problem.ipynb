{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matt-Muscedere/Projects/blob/main/COMP_3710_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkbwwMUNCicA"
      },
      "source": [
        "# Imports & Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RrDVW2DGJIJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUX15rTIsU9s"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import svm, datasets\n",
        "\n",
        "attribute_names = ['cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat']\n",
        "\n",
        "# @article{scikit-learn,\n",
        "#  title={Scikit-learn: Machine Learning in {P}ython},\n",
        "#  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n",
        "#          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n",
        "#          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n",
        "#          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n",
        "#  journal={Journal of Machine Learning Research},\n",
        "#  volume={12},\n",
        "#  pages={2825--2830},\n",
        "#  year={2011}\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX2ZOItMCVGX"
      },
      "source": [
        "# Preparing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMNmUTGPCb2N"
      },
      "source": [
        "## Importing the training data csv file into Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XpLMYAKCnZ2"
      },
      "outputs": [],
      "source": [
        "print(f', '.join(attribute_names))\n",
        "\n",
        "X_data = []\n",
        "y_data = []\n",
        "\n",
        "data_url = \"https://raw.githubusercontent.com/kkatanaga/UW-Coursework/master/COMP%203710/agaricus-lepiota.data\"\n",
        "data_list = pd.read_csv(data_url, header=None).values.tolist()\n",
        "\n",
        "# Split data_list to 2 lists\n",
        "for row in data_list:\n",
        "    X_data.append(row[1:])\n",
        "    y_data.append(row[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGxt-DhuIbFb"
      },
      "source": [
        "## Converting training data into sklearn-readable data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTDy9TG7If4H"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 80:20 Split\n",
        "raw_X_train, raw_X_test, raw_y_train, raw_y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=22)\n",
        "\n",
        "# Encode X\n",
        "one_hot_enc = OneHotEncoder()\n",
        "X_train = one_hot_enc.fit_transform(raw_X_train).toarray()\n",
        "X_test = one_hot_enc.transform(raw_X_test).toarray()\n",
        "\n",
        "# Encode y\n",
        "label_enc = LabelEncoder()\n",
        "y_train = label_enc.fit_transform(raw_y_train)\n",
        "y_test = label_enc.transform(raw_y_test)\n",
        "\n",
        "print(raw_X_train)\n",
        "print(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZwR8UHYhncx"
      },
      "source": [
        "## Calculate the ratio of rank 1 instances among the grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_pIgCqWhrol"
      },
      "outputs": [],
      "source": [
        "def rank_one_ratio(ranking):\n",
        "    rank_one_count = 0\n",
        "    for i in ranking:\n",
        "        if i == 1:\n",
        "            rank_one_count += 1\n",
        "    total_count = len(ranking)\n",
        "    print(f'Number of rank 1 instances: {rank_one_count}')\n",
        "    print(f'Total instances: {total_count}')\n",
        "    print(f'Rank 1 ratio: {rank_one_count / total_count}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQT3uWZHIjaf"
      },
      "source": [
        "# Functions & Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg_ilLlNIwHK"
      },
      "source": [
        "## Randomized Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1i8nakAIv3b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_forest_model = RandomForestClassifier(n_estimators=10)\n",
        "print(random_forest_model.get_params())\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "y_predict = random_forest_model.predict(X_test)\n",
        "print(\"Accuracy:\", f1_score(y_test, y_predict, average='micro'))\n",
        "print(y_test)\n",
        "print(y_predict)\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": [1, 3, 10, 100],\n",
        "    \"max_features\": [1, 3, 10, None],\n",
        "    \"max_depth\": [1, 3, 10, None],\n",
        "    \"max_leaf_nodes\": [2, 5, 10, None],\n",
        "    \"bootstrap\": [True, False]\n",
        "}\n",
        "\n",
        "random_forest_model2 = RandomForestClassifier()\n",
        "search = GridSearchCV(random_forest_model2, params, scoring='accuracy')\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(search.best_estimator_)\n",
        "print(search.best_score_)\n",
        "print(search.best_params_)\n",
        "\n",
        "best_random_forest = search.best_estimator_\n",
        "\n",
        "# Fit the classifier on the training data using the best hyperparameters\n",
        "best_random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the best classifier\n",
        "predictions = best_random_forest.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = f1_score(y_test, predictions, average='micro')\n",
        "print(\"Accuracy: \", accuracy)\n",
        "rank_one_ratio(search.cv_results_['rank_test_score'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-x-W02AIzCG"
      },
      "source": [
        "## Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2h48R1EI7MS"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.tree import export_text\n",
        "\n",
        "\"\"\"\n",
        "# Create Decision Tree classifer object\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "# Predict the response for test dataset\n",
        "y_predict = clf.predict(X_test)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=2)\n",
        "\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "y_predict = clf.predict(X_test)\n",
        "\"\"\"\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=2)\n",
        "\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "y_predict = clf.predict(X_test)\n",
        "\n",
        "print(y_predict)\n",
        "print(y_test)\n",
        "print(\"Accuracy:\", f1_score(y_test, y_predict, average='micro'))\n",
        "\n",
        "# Define the hyperparameters to tune\n",
        "params = {\n",
        "    \"criterion\": ['gini', 'entropy'],\n",
        "    \"max_depth\": [1, 2, 3, 4, 5, 10, 20, 25, 30],\n",
        "    \"min_samples_split\": [2, 3, 4, 5, 10, 20, 30],\n",
        "    \"min_samples_leaf\": [1, 2, 3, 4, 5, 10, 20]\n",
        "}\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(clf, params, cv=5, verbose=1, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best hyperparameter using gridsearch are \", grid_search.best_params_)\n",
        "print(grid_search.best_estimator_)\n",
        "print(\"Best score: \", grid_search.best_score_)\n",
        "\n",
        "# Use the best hyperparameters to create a new instance of the classifier\n",
        "best_clf = tree.DecisionTreeClassifier(criterion=grid_search.best_params_['criterion'],\n",
        "                                        max_depth=grid_search.best_params_['max_depth'],\n",
        "                                        min_samples_split=grid_search.best_params_['min_samples_split'],\n",
        "                                        min_samples_leaf=grid_search.best_params_['min_samples_leaf'])\n",
        "\n",
        "# Fit the classifier on the training data using the best hyperparameters\n",
        "best_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the best classifier\n",
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = f1_score(y_test, y_pred, average='micro')\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "r = export_text(best_clf)\n",
        "print(\"textual format:\")\n",
        "print(r)\n",
        "\n",
        "rank_one_ratio(grid_search.cv_results_['rank_test_score'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHIX8q11I3XH"
      },
      "source": [
        "## Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewQtAUC9I77A"
      },
      "outputs": [],
      "source": [
        "# KNeighborsClassifier class specificcaly implements the k-nearest neighbors algorithm for classification\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the KNN model\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Define hyperparameters to search\n",
        "param_grid = {'n_neighbors': [3, 5, 7, 9],\n",
        "              'weights': ['uniform', 'distance'],\n",
        "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
        "\n",
        "# Use grid search to find best hyperparameters\n",
        "grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Print best hyperparameters and corresponding accuracy score\n",
        "print(\"Best hyperparameters using grid search are \", grid.best_params_)\n",
        "print(\"Best model found: \", grid.best_estimator_)\n",
        "print(\"Best score: \", grid.best_score_)\n",
        "\n",
        "\n",
        "# Use the best model to make predictions on the test set\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "\n",
        "# Print the predicted labels and the true labels for the test set\n",
        "print(\"Predicted labels: \")\n",
        "print(np.array2string(y_pred, separator=', '))\n",
        "print(\"True labels: \")\n",
        "print(np.array2string(y_test, separator=', '))\n",
        "\n",
        "# Print the accuracy of the best model on the test set\n",
        "accuracy = grid.best_estimator_.score(X_test, y_test)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "rank_one_ratio(grid.cv_results_['rank_test_score'])\n",
        "\n",
        "#####\n",
        "# NearestNeighbors returns indices of the nearest neighbors for each sample in the input data\n",
        "\n",
        "# from sklearn.neighbors import NearestNeighbors\n",
        "# import numpy as np\n",
        "# nn_model = NearestNeighbors(n_neighbors=3)\n",
        "# nn_model.fit(X_train)\n",
        "# neighbors = nn_model.kneighbors(X_test, return_distance=False)\n",
        "# y_predict = np.array([np.bincount(y_train[neighbor]).argmax() for neighbor in neighbors])\n",
        "# print(y_predict)\n",
        "\n",
        "#####\n",
        "\n",
        "# # Define the classifier with desired hyperparameters\n",
        "# knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski')\n",
        "\n",
        "# # Train the classifier using the training data\n",
        "# knn.fit(X_train, y_train)\n",
        "\n",
        "# # Use the trained classifier to predict labels for the test data\n",
        "# y_pred = knn.predict(X_test)\n",
        "\n",
        "# # Compute the F1 score to evaluate the performance of the classifier\n",
        "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "# print('F1 score:', f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2cNX1UGIqA7"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tJHx-ywI8RP"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "svm = svm.SVC()\n",
        "\n",
        "svm_parameters = {'C': [0.5, 1.0, 2.0, 10.0, 100.0], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'degree': [2, 3, 4],'gamma': ['scale', 'auto'], 'cache_size': [1000]}\n",
        "\n",
        "svm_grid = GridSearchCV(svm, svm_parameters, cv=5, scoring='accuracy')\n",
        "svm_grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best model: {svm_grid.best_estimator_}\" )\n",
        "print(f\"Mean score of best model: {svm_grid.best_score_}\")\n",
        "\n",
        "svm_y_predict = svm_grid.best_estimator_.predict(X_test)\n",
        "\n",
        "svm_score = svm_grid.best_estimator_.score(X_test, y_test)\n",
        "print(f\"average score: {svm_score}\")\n",
        "\n",
        "svm_f1_score = f1_score(y_test, svm_y_predict)\n",
        "print(f\"f1 score: {svm_f1_score}\")\n",
        "\n",
        "svm_f1_micro = f1_score(y_test, svm_y_predict, average='micro')\n",
        "print(f\"f1 micro score: {svm_f1_micro}\")\n",
        "\n",
        "##################################\n",
        "\n",
        "# svm_parameters = {'C': [0.5, 1.0, 2.0, 10.0, 100.0], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'degree': [2, 3, 4],'gamma': ['scale', 'auto'], 'cache_size': [1000]}\n",
        "# Best model: SVC(C=0.5, cache_size=1000, degree=2, kernel='linear')\n",
        "# Mean score of best model: 1.0\n",
        "# average score: 1.0\n",
        "# f1 score: 1.0\n",
        "# f1 micro score: 1.0\n",
        "\n",
        "# svm_parameters = {'C': [0.5, 1.0, 2.0, 10.0, 100.0], 'kernel': ['poly', 'rbf', 'sigmoid'],'degree': [2, 3, 4],'gamma': ['scale', 'auto'], 'cache_size': [1000]}\n",
        "# Best model: SVC(C=0.5, cache_size=1000, kernel='poly')\n",
        "# Mean score of best model: 1.0\n",
        "# average score: 1.0\n",
        "# f1 score: 1.0\n",
        "# f1 micro score: 1.0\n",
        "\n",
        "# svm_parameters = {'C': [0.5, 1.0, 2.0, 10.0, 100.0], 'kernel': ['rbf'],'gamma': ['scale', 'auto'], 'cache_size': [1000]}\n",
        "# Best model: SVC(cache_size=1000)\n",
        "# Mean score of best model: 1.0\n",
        "# average score: 1.0\n",
        "# f1 score: 1.0\n",
        "# f1 micro score: 1.0\n",
        "\n",
        "# svm_parameters = {'C': [0.5, 1.0, 2.0, 10.0, 100.0], 'kernel': ['sigmoid'],'gamma': ['scale', 'auto'], 'cache_size': [1000]}\n",
        "# Best model: SVC(C=100.0, cache_size=1000, gamma='auto', kernel='sigmoid')\n",
        "# Mean score of best model: 1.0\n",
        "# average score: 1.0\n",
        "# f1 score: 1.0\n",
        "# f1 micro score: 1.0\n",
        "\n",
        "# svm_parameters = {'C': [0.1, 0.25, 0.5, 0.75, 1.0], 'kernel': ['linear'], 'cache_size': [1000]}\n",
        "# Best model: SVC(C=0.25, cache_size=1000, kernel='linear')\n",
        "# Mean score of best model: 1.0\n",
        "# average score: 1.0\n",
        "# f1 score: 1.0\n",
        "# f1 micro score: 1.0\n",
        "\n",
        "# svm_parameters = {'C': [0.1], 'kernel': ['linear'], 'cache_size': [1000]}\n",
        "# Best model: SVC(C=0.1, cache_size=1000, kernel='linear')\n",
        "# Mean score of best model: 0.9992307692307693\n",
        "# average score: 0.9987692307692307\n",
        "# f1 score: 0.998689384010485\n",
        "# f1 micro score: 0.9987692307692307\n",
        "\n",
        "#\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
